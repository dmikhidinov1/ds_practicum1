{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf6c6493",
   "metadata": {},
   "source": [
    "# MSDS692_X41_Data Science Practicum \n",
    "## Dilyor Mikhidinov\n",
    "Using Convolutional Neural Networks to classify Malaria Cell Images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e3c3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing neccessary libraries:\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "\n",
    "#ML libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.applications import MobileNetV2, VGG19\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout, InputLayer, Reshape, Conv1D, MaxPool1D, SeparableConv2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import cross_validate, train_test_split\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"dataset/cell_images\")) #folder where the dataset is located"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfeb1297",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85544cc6",
   "metadata": {},
   "source": [
    "#### Checking if all the libraries are working properly. I have had very big issues with installing tensorflow_gpu and openCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6969c4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a522b07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5a8d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install opencv_python-4.5.5-cp38-cp38-win_amd64.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9b85c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ccfa92",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0291d3d6",
   "metadata": {},
   "source": [
    "Next I'm going to create seperate directory to manage labelled data. For fulfilling this task I am using shutil(https://docs.python.org/3/library/shutil.html) library. It allows variety of high-level operations on files (collection, copying and removal of files). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda8932e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "base_dir = 'dataset/cell_images'\n",
    "work_dir  = 'work/'\n",
    "os.mkdir(work_dir)\n",
    "\n",
    "base_dir_Positive = 'dataset/cell_images/Parasitized/' \n",
    "base_dir_Negative = 'dataset/cell_images/Uninfected/'\n",
    "\n",
    "work_dir_Positive = 'work/Positive/'\n",
    "os.mkdir(work_dir_Positive)\n",
    "work_dir_Negative = 'work/Negative/'\n",
    "os.mkdir(work_dir_Negative)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b57b925",
   "metadata": {},
   "source": [
    "Now we have work directory. Time to create training, validation and test folders with neg/pos (folder for negative and positive labelled images) inside each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb1f414",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = os.path.join(work_dir, 'train')\n",
    "os.mkdir(train_dir)\n",
    "\n",
    "validation_dir = os.path.join(work_dir, 'validation')\n",
    "os.mkdir(validation_dir)\n",
    "\n",
    "test_dir = os.path.join(work_dir, 'test')\n",
    "os.mkdir(test_dir)\n",
    "\n",
    "print(\"New directories for train, validation, and test created\")\n",
    "train_pos_dir = os.path.join(train_dir, 'pos')\n",
    "os.mkdir(train_pos_dir)\n",
    "train_neg_dir = os.path.join(train_dir, 'neg')\n",
    "os.mkdir(train_neg_dir)\n",
    "\n",
    "validation_pos_dir = os.path.join(validation_dir, 'pos')\n",
    "os.mkdir(validation_pos_dir)\n",
    "validation_neg_dir = os.path.join(validation_dir, 'neg')\n",
    "os.mkdir(validation_neg_dir)\n",
    "\n",
    "test_pos_dir = os.path.join(test_dir, 'pos')\n",
    "os.mkdir(test_pos_dir)\n",
    "test_neg_dir = os.path.join(test_dir, 'neg')\n",
    "os.mkdir(test_neg_dir)\n",
    "\n",
    "print(\"Train, Validation, and Test folders made for both Positive and Negative datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c08a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "      \n",
    "for filename in os.listdir(base_dir_Positive): \n",
    "    dst =\"pos\" + str(i) + \".jpg\"\n",
    "    src =base_dir_Positive + filename \n",
    "    dst =work_dir_Positive + dst \n",
    "          \n",
    "       # rename() function will \n",
    "       # rename all the files \n",
    "    shutil.copy(src, dst) \n",
    "    i += 1\n",
    "\n",
    "\n",
    "j = 0\n",
    "\n",
    "for filename in os.listdir(base_dir_Negative): \n",
    "    dst =\"neg\" + str(j) + \".jpg\"\n",
    "    src =base_dir_Negative + filename \n",
    "    dst =work_dir_Negative + dst \n",
    "          \n",
    "    # rename() function will \n",
    "    # rename all the files \n",
    "    shutil.copy(src, dst) \n",
    "    j += 1       \n",
    "        \n",
    "print(\"Images for both categories have been copied to working directories, renamed to <pos & neg + index> \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac58b0b",
   "metadata": {},
   "source": [
    "#### Next I am manually splitting all \"Positive\" labelled images into training, test and validation folders in 80%-10%-10% respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e466496",
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames = ['pos{}.jpg'.format(i) for i in range(11000)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(work_dir_Positive, fname)\n",
    "    dst = os.path.join(train_pos_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "\n",
    "fnames = ['pos{}.jpg'.format(i) for i in range(11000, 12390)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(work_dir_Positive, fname)\n",
    "    dst = os.path.join(validation_pos_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "\n",
    "fnames = ['pos{}.jpg'.format(i) for i in range(12390, 13780)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(work_dir_Positive, fname)\n",
    "    dst = os.path.join(test_pos_dir, fname)\n",
    "    shutil.copyfile(src, dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6aa7a5f",
   "metadata": {},
   "source": [
    "#### Next doing the same thing for \"Negative\" labelled images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aec597f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames = ['neg{}.jpg'.format(i) for i in range(11000)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(work_dir_Negative, fname)\n",
    "    dst = os.path.join(train_neg_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "\n",
    "fnames = ['neg{}.jpg'.format(i) for i in range(11000, 12390)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(work_dir_Negative, fname)\n",
    "    dst = os.path.join(validation_neg_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "\n",
    "fnames = ['neg{}.jpg'.format(i) for i in range(12390, 13780)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(work_dir_Negative, fname)\n",
    "    dst = os.path.join(test_neg_dir, fname)\n",
    "    shutil.copyfile(src, dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19bf478",
   "metadata": {},
   "source": [
    "#### Lets view distribution of images in each folder we created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4678ff4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train, validation, and test datasets split and ready for use\")\n",
    "print('total training pos images:', len(os.listdir(train_pos_dir)))\n",
    "print('total training neg images:', len(os.listdir(train_neg_dir)))\n",
    "print('total validation pos images:', len(os.listdir(validation_pos_dir)))\n",
    "print('total validation neg images:', len(os.listdir(validation_neg_dir)))\n",
    "print('total test pos images:', len(os.listdir(test_pos_dir)))\n",
    "print('total test neg images:', len(os.listdir(test_neg_dir)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb57874f",
   "metadata": {},
   "source": [
    "## Image Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3bb922f",
   "metadata": {},
   "source": [
    "Next I am going to use one of the powerful tools of tensorflow.keras called \"ImageDataGenerator\". This function allows us to take the path to a directory and generate batches of augmented data. Augmentation is important step in almost every Deep learning analysis. Since it allows to modify the existing data we are using in multiple manners so that the trained algorithm becomes capable of generating patterns for even more variety of images. The only case that Augmentation might not be applicable is when the goal is for example to predict the road signs for self driving cars. Signs are always fixed and do not appear for example in vertically flipped way in reality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec889fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6d114c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = datagen.flow_from_directory(directory = train_dir,\n",
    "                                                    target_size=(128, 128),\n",
    "                                                    class_mode='binary',\n",
    "                                                    #subset='training',\n",
    "                                                    shuffle=True,\n",
    "                                                    batch_size=32)\n",
    "\n",
    "valid_generator = datagen.flow_from_directory(directory = validation_dir,\n",
    "                                                   target_size=(128, 128),\n",
    "                                                   class_mode='binary',\n",
    "                                                   #subset='validation',\n",
    "                                                   shuffle = True,\n",
    "                                                   batch_size=32)\n",
    "\n",
    "\n",
    "classes = ['Parasitized', 'Uninfected']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26581b75",
   "metadata": {},
   "source": [
    "## Some Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc7d9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_training_images, train_label = next(train_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45bf6c11",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def displayImages(images_arr):\n",
    "    fig, axes = plt.subplots(1, 5, figsize=(20,20))\n",
    "    axes = axes.flatten()\n",
    "    for img, ax in zip(images_arr, axes):\n",
    "        ax.imshow(img)\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout() \n",
    "    plt.show()\n",
    "print('Random Display of Cell images from Training set')\n",
    "displayImages(sample_training_images[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f96131",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    img=cv2.imread(work_dir_Positive[i])\n",
    "    plt.imshow(img)\n",
    "    plt.title(\"Parasitized\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1f9a26",
   "metadata": {},
   "source": [
    "## Looking at different CNN models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0668ae7",
   "metadata": {},
   "source": [
    "During the project timeline I viewed different CNN models and checked their performances with evaluation metrics. And from the analysis I selected top 3 best performing models: DS-CNN, VGG19-InceptionV3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1301364",
   "metadata": {},
   "source": [
    "#### Depth-Wise Separable CNN (DS-CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe7e8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_length = 128,128,3\n",
    "\n",
    "ds_model = Sequential()\n",
    "ds_model.add(Conv2D(16,(3,3),activation='relu',input_shape=(128,128,3)))\n",
    "ds_model.add(MaxPool2D(2,2))\n",
    "ds_model.add(Dropout(0.2))\n",
    "\n",
    "ds_model.add(Conv2D(32,(3,3),activation='relu'))\n",
    "ds_model.add(MaxPool2D(2,2))\n",
    "ds_model.add(Dropout(0.2))\n",
    "\n",
    "ds_model.add(SeparableConv2D(64,(3,3),activation='relu'))\n",
    "ds_model.add(MaxPool2D(2,2))\n",
    "ds_model.add(Dropout(0.3))\n",
    "\n",
    "ds_model.add(SeparableConv2D(128,(3,3),activation='relu'))\n",
    "ds_model.add(MaxPool2D(2,2))\n",
    "ds_model.add(Dropout(0.3))\n",
    "\n",
    "ds_model.add(Flatten())\n",
    "ds_model.add(Dense(64,activation='relu'))\n",
    "ds_model.add(Dropout(0.5))\n",
    "\n",
    "ds_model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.0005, beta_1=0.9, beta_2=0.999)\n",
    "ds_model.compile(optimizer= opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "ds_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fb2ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988947d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = ds_model.fit(train_generator,\n",
    "                              epochs=100,\n",
    "                              steps_per_epoch= len(train_generator),\n",
    "                              validation_data = (valid_generator),\n",
    "                              #callbacks = [early_stop]\n",
    "                              #verbose=1\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1448755",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_model.save(work_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c65703",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_training(history, lw = 3):\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.plot(history.history['accuracy'], label = 'training', marker = '*', linewidth = lw)\n",
    "    plt.plot(history.history['val_accuracy'], label = 'validation', marker = 'o', linewidth = lw)\n",
    "    plt.title('Training Accuracy vs Validation Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend(fontsize = 'x-large')\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.plot(history.history['loss'], label = 'training', marker = '*', linewidth = lw)\n",
    "    plt.plot(history.history['val_loss'], label = 'validation', marker = 'o', linewidth = lw)\n",
    "    plt.title('Training Loss vs Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend(fontsize = 'x-large')\n",
    "    plt.show()\n",
    "visualize_training(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39ef424",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = history.history['accuracy']\n",
    "loss = history.history['loss']\n",
    "val_accuracy = history.history['val_accuracy']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "print(f'Training Accuracy: {np.max(accuracy)}')\n",
    "print(f'Training Loss: {np.min(loss)}')\n",
    "print(f'Validation Accuracy: {np.max(val_accuracy)}')\n",
    "print(f'Validation Loss: {np.min(val_loss)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b072307",
   "metadata": {},
   "source": [
    "As we can see DS_CNN performaned really good on training with excellent performance metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59d0175",
   "metadata": {},
   "source": [
    "## VGG19 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5300b4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_model = Sequential()\n",
    "vgg_model.add(VGG19(include_top=False, pooling='avg', weights='imagenet', input_shape=(128, 128, 3), classes=2))\n",
    "vgg_model.add(Flatten())\n",
    "vgg_model.add(Dense(256,activation='relu'))\n",
    "vgg_model.add(Dense(64,activation='relu'))\n",
    "vgg_model.add(Dense(1,activation = 'sigmoid'))\n",
    "\n",
    "vgg_model.layers[0].trainable = False\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.00005, beta_1=0.9, beta_2=0.999)\n",
    "vgg_model.compile(optimizer= opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "vgg_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a420e090",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Other models that I am going to be looking at are for comparison of performance only. Thats why I am going 50 epochs\n",
    "\n",
    "vgg_history = vgg_model.fit(train_generator,\n",
    "                                      steps_per_epoch = len(train_generator),\n",
    "                                      epochs=50,\n",
    "                                      validation_steps = len(valid_generator),\n",
    "                                      validation_data = valid_generator,\n",
    "                                      verbose=1\n",
    "                                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3648dbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_training(vgg_history, lw = 3):\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.plot(vgg_history.history['accuracy'], label = 'training', marker = '*', linewidth = lw)\n",
    "    plt.plot(vgg_history.history['val_accuracy'], label = 'validation', marker = 'o', linewidth = lw)\n",
    "    plt.title('Training Accuracy vs Validation Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend(fontsize = 'x-large')\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.plot(vgg_history.history['loss'], label = 'training', marker = '*', linewidth = lw)\n",
    "    plt.plot(vgg_history.history['val_loss'], label = 'validation', marker = 'o', linewidth = lw)\n",
    "    plt.title('Training Loss vs Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend(fontsize = 'x-large')\n",
    "    plt.show()\n",
    "visualize_training(vgg_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd11cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = vgg_history.history['accuracy']\n",
    "loss = vgg_history.history['loss']\n",
    "val_accuracy = vgg_history.history['val_accuracy']\n",
    "val_loss = vgg_history.history['val_loss']\n",
    "\n",
    "print(f'Training Accuracy: {np.max(accuracy)}')\n",
    "print(f'Training Loss: {np.min(loss)}')\n",
    "print(f'Validation Accuracy: {np.max(val_accuracy)}')\n",
    "print(f'Validation Loss: {np.min(val_loss)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22cff01f",
   "metadata": {},
   "source": [
    "VGG19 Model is also performing really good, but compared to DS_CNN a little lower Accuracy and higher Validation Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b68c10",
   "metadata": {},
   "source": [
    "## Inception Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ef2a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "inc_model = Sequential()\n",
    "inc_model.add(tf.keras.applications.InceptionV3(include_top=False, pooling='avg', weights='imagenet', input_shape=(128, 128, 3), classes=2))\n",
    "inc_model.add(Flatten())\n",
    "inc_model.add(Dense(64,activation='relu'))\n",
    "inc_model.add(Dense(1,activation = 'sigmoid'))\n",
    "\n",
    "inc_model.layers[0].trainable = False\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.00005, beta_1=0.9, beta_2=0.999)\n",
    "\n",
    "inc_model.compile(optimizer= opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "inc_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d2ccca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inc_history = inc_model.fit(train_generator,\n",
    "                            steps_per_epoch = len(train_generator),\n",
    "                            epochs=50,\n",
    "                            validation_data=valid_generator,\n",
    "                            verbose=1\n",
    "                                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb9c232",
   "metadata": {},
   "outputs": [],
   "source": [
    "inc_model_s = 'inceptionv3_malaria_predsmodel.h5'\n",
    "inc_model.save(inc_model_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0e448f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_training(inc_history, lw = 3):\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.plot(inc_history.history['accuracy'], label = 'training', marker = '*', linewidth = lw)\n",
    "    plt.plot(inc_history.history['val_accuracy'], label = 'validation', marker = 'o', linewidth = lw)\n",
    "    plt.title('Training Accuracy vs Validation Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend(fontsize = 'x-large')\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.plot(inc_history.history['loss'], label = 'training', marker = '*', linewidth = lw)\n",
    "    plt.plot(inc_history.history['val_loss'], label = 'validation', marker = 'o', linewidth = lw)\n",
    "    plt.title('Training Loss vs Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend(fontsize = 'x-large')\n",
    "    plt.show()\n",
    "visualize_training(inc_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2046bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b47f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = inc_history.history['accuracy']\n",
    "loss = inc_history.history['loss']\n",
    "val_accuracy = inc_history.history['val_accuracy']\n",
    "val_loss = inc_history.history['val_loss']\n",
    "\n",
    "print(f'Training Accuracy: {np.max(accuracy)}')\n",
    "print(f'Training Loss: {np.min(loss)}')\n",
    "print(f'Validation Accuracy: {np.max(val_accuracy)}')\n",
    "print(f'Validation Loss: {np.min(val_loss)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07dbfd78",
   "metadata": {},
   "source": [
    "Looks like Inception model is not performing really well. We can clearly see the validation loss skyrocketting in the end of training cycle. That is obviously situation of Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfaf1d7c",
   "metadata": {},
   "source": [
    "## Evaluating Models on Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61b8e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#eval_datagen = ImageDataGenerator(rescale=1./255)\n",
    "eval_generator = test_datagen.flow_from_directory(directory = test_dir,\n",
    "                                                   target_size=(128, 128),\n",
    "                                                   class_mode=None,\n",
    "                                                   shuffle = False,\n",
    "                                                   batch_size=32\n",
    "                                                 )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee8aa3e",
   "metadata": {},
   "source": [
    "#### Depth-Wise Separable CNN (DS-CNN) evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3744c8c6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "eval_generator.reset()    \n",
    "pred_ds_cnn = ds_model.predict(eval_generator, 1000, verbose=1)\n",
    "print(\"Predictions finished\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fce35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "\n",
    "for index, probability in enumerate(pred_ds_cnn):\n",
    "    image_path = test_dir + \"/\" +eval_generator.filenames[index]\n",
    "    img = mpimg.imread(image_path)\n",
    "\n",
    "    plt.imshow(img)\n",
    "    print(eval_generator.filenames[index])\n",
    "    if probability > 0.5:\n",
    "        plt.title(\"%.2f\" % (probability[0]*100) + \"% B\")\n",
    "    else:\n",
    "        plt.title(\"%.2f\" % ((1-probability[0])*100) + \"% A\")\n",
    "    plt.show()\n",
    "    \n",
    " \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79bd10d3",
   "metadata": {},
   "source": [
    "#### VGG19 Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1508c531",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_generator.reset()    \n",
    "pred_vgg = vgg_model.predict(eval_generator, 50, verbose=1)\n",
    "print(\"Predictions finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7b6694",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "\n",
    "for index, probability in enumerate(pred_vgg):\n",
    "    image_path = test_dir + \"/\" +eval_generator.filenames[index]\n",
    "    img = mpimg.imread(image_path)\n",
    "\n",
    "    plt.imshow(img)\n",
    "    print(eval_generator.filenames[index])\n",
    "    if probability > 0.5:\n",
    "        plt.title(\"%.2f\" % (probability[0]*100) + \"% B\")\n",
    "    else:\n",
    "        plt.title(\"%.2f\" % ((1-probability[0])*100) + \"% A\")\n",
    "    plt.show()\n",
    "    \n",
    " \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0525b6",
   "metadata": {},
   "source": [
    "#### Inception Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d236a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_generator.reset()    \n",
    "pred_inception = inc_model.predict(eval_generator, 50, verbose=1)\n",
    "print(\"Predictions finished\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7932cbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "\n",
    "for index, probability in enumerate(pred_inception):\n",
    "    image_path = test_dir + \"/\" +eval_generator.filenames[index]\n",
    "    img = mpimg.imread(image_path)\n",
    "\n",
    "    plt.imshow(img)\n",
    "    print(eval_generator.filenames[index])\n",
    "    if probability > 0.5:\n",
    "        plt.title(\"%.2f\" % (probability[0]*100) + \"% B\")\n",
    "    else:\n",
    "        plt.title(\"%.2f\" % ((1-probability[0])*100) + \"% A\")\n",
    "    plt.show()\n",
    "    \n",
    " \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef21503",
   "metadata": {},
   "source": [
    "## Trying one more CNN model but using OpenCV for Image Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68122217",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 120\n",
    "CATEGORIES = ['Parasitized', 'Uninfected']\n",
    "dataset = []\n",
    "\n",
    "def generate_data():\n",
    "    for category in CATEGORIES:\n",
    "        path = f'dataset/cell_images/{category}'\n",
    "        class_id = CATEGORIES.index(category)\n",
    "        for image in os.listdir(path):\n",
    "            try:\n",
    "                image_array = cv2.imread(os.path.join(path, image), cv2.IMREAD_COLOR)\n",
    "                image_array = cv2.resize(image_array, (IMG_SIZE , IMG_SIZE))\n",
    "                dataset.append([image_array, class_id])\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "    random.shuffle(dataset)\n",
    "                \n",
    "generate_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88644364",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea96edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "labels = []\n",
    "for features, label in dataset:\n",
    "    data.append(features)\n",
    "    labels.append(label)\n",
    "\n",
    "data = np.array(data)\n",
    "data.reshape(-1, 120, 120, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4288c3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, data, train_labels, labels = train_test_split(data, \n",
    "                                                          labels,\n",
    "                                                          test_size=0.15)\n",
    "\n",
    "test_data, validation_data, test_labels, validation_labels = train_test_split(data, \n",
    "                                                                    labels,\n",
    "                                                                    test_size=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6699337b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "i = 0\n",
    "for i in range(25):\n",
    "    plt.subplot(5, 5, i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.imshow(test_data[i])\n",
    "    if(test_labels[i] == 0):\n",
    "        plt.xlabel('Infected')\n",
    "    else:\n",
    "        plt.xlabel('Uninfected')\n",
    "    i += 1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8916de71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image Augmentation\n",
    "datagen_train = ImageDataGenerator(rescale=1./255,\n",
    "                            rotation_range=45,\n",
    "                            width_shift_range=0.2,\n",
    "                            height_shift_range=0.2,\n",
    "                            shear_range=0.2,\n",
    "                            zoom_range=0.2,\n",
    "                            horizontal_flip=True)\n",
    "\n",
    "datagen_test = ImageDataGenerator(rescale=1./255)\n",
    "datagen_validation = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00fcd464",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen_train.fit(train_data)\n",
    "datagen_test.fit(test_data)\n",
    "datagen_test.fit(validation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f15a356",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 3)),\n",
    "    MaxPool2D((2, 2)),\n",
    "    \n",
    "    Conv2D(64, (3, 3), activation=\"relu\"),\n",
    "    MaxPool2D((2, 2)),\n",
    "    \n",
    "    Conv2D(128, (3, 3), activation=\"relu\"),\n",
    "    MaxPool2D((2, 2)),\n",
    "    \n",
    "    Conv2D(256, (3, 3), activation=\"relu\"),\n",
    "    MaxPool2D((2, 2)),\n",
    "    \n",
    "    Flatten(),\n",
    "    Dense(256, activation=\"relu\"),\n",
    "    Dense(2, activation='softmax')\n",
    "])\n",
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544009a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11df15b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = cnn_model.fit_generator(datagen_train.flow(train_data, train_labels, batch_size=32),\n",
    "                   steps_per_epoch=len(train_data) / 32,\n",
    "                   epochs=50,validation_data=datagen_validation.flow\n",
    "                              (validation_data,validation_labels, batch_size=32),                    \n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560284b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_training(history, lw = 3):\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.plot(inc_history.history['accuracy'], label = 'training', marker = '*', linewidth = lw)\n",
    "    plt.plot(inc_history.history['val_accuracy'], label = 'validation', marker = 'o', linewidth = lw)\n",
    "    plt.title('Training Accuracy vs Validation Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend(fontsize = 'x-large')\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.plot(inc_history.history['loss'], label = 'training', marker = '*', linewidth = lw)\n",
    "    plt.plot(inc_history.history['val_loss'], label = 'validation', marker = 'o', linewidth = lw)\n",
    "    plt.title('Training Loss vs Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend(fontsize = 'x-large')\n",
    "    plt.show()\n",
    "visualize_training(inc_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97917a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = history.history['accuracy']\n",
    "loss = history.history['loss']\n",
    "val_accuracy = history.history['val_accuracy']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "print(f'Training Accuracy: {np.max(accuracy)}')\n",
    "print(f'Training Loss: {np.min(loss)}')\n",
    "print(f'Validation Accuracy: {np.max(val_accuracy)}')\n",
    "print(f'Validation Loss: {np.min(val_loss)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85368d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(test_data)\n",
    "predictions = cnn_model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d19308",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['Infected', 'Uninfected']\n",
    "def plot_images(i, predictions_array, true_labels, images):\n",
    "    predictions_array, true_label, img = predictions_array[i], true_labels[i],images[i]\n",
    "    plt.grid(False)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    \n",
    "    plt.imshow(img)\n",
    "    \n",
    "    predicted_label = np.argmax(predictions_array)\n",
    "        \n",
    "    plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n",
    "                                        100*np.max(predictions_array),\n",
    "                                        class_names[true_label]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ce1463",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d0accb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "num_rows = 100\n",
    "num_cols = 4\n",
    "num_images = num_rows * num_cols\n",
    "plt.figure(figsize=(2*2*num_cols, 2*num_rows))\n",
    "for i in range(num_images):\n",
    "    plt.subplot(num_rows, 2*num_cols, 2*i+1)\n",
    "    plot_images(i, predictions, test_labels, test_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
